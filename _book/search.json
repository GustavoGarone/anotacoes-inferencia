[
  {
    "objectID": "intervalos-confianca.html",
    "href": "intervalos-confianca.html",
    "title": "38  Intervalos de Confiança - Aprofundamento",
    "section": "",
    "text": "38.1 Interpretação em termos de repetições:\nSeja \\(\\boldsymbol{X}_n = (X_1,\\dots,X_n)\\) amostra aleatória e \\(X \\sim f_\\theta, \\theta \\in \\Theta\\).\nDizemos que \\([I_1(\\boldsymbol{X}_n), I_2(\\boldsymbol{X}_n)]\\) é um intervalo de confiança exato para \\(g(\\theta)\\) com coeficiente de confiança \\(\\gamma \\in (0,1)\\) se, e somente se: \\[\nP_\\theta\\left(I_1(\\boldsymbol{X}_n) \\leq g(\\theta) \\leq I_2(\\boldsymbol{X}_n)\\right) = \\gamma, \\forall \\theta \\in \\Theta.\n\\] em que \\(I_1(\\boldsymbol{X}_n), I_2(\\boldsymbol{X}_n)\\) são estatísticas.\nObserve que \\(\\mathrm{IC}(g(\\theta),\\gamma)\\) é um intervalo aleatório que não depende de “\\(\\theta\\)”.\nNa prática, observamos a amostra \\(\\boldsymbol{x}_n = (x_1, \\dots, x_n)\\) e calculamos o IC observado\nPortanto, \\[\nP_\\theta\\left(I_1(\\boldsymbol{X}_n) \\leq g(\\theta) \\leq I_2(\\boldsymbol{X}_n)\\right) =\n\\begin{cases}\n1, g(\\theta) \\in \\mathrm{IC}_{\\mathrm{Obs}}(g(\\theta), \\gamma) \\\\\n0, \\mathrm{c.c.}\n\\end{cases}\n\\]\nSe repetirmos o experimento, mantendo as mesmas condições, então esperamos que em \\(\\gamma \\cdot 100\\%\\) dos experimentos os ICs contenham \\(g(\\theta)\\). Em outras palavras, \\[\n\\begin{aligned}\n\\#\\frac{(g(\\theta) \\in \\mathrm{IC}_{\\mathrm{Obs}})}{N} \\approx \\gamma \\\\\n\\left[\n\\frac{1}{N} \\sum \\mathbb{1}_{\\{\\mathrm{IC}_{\\mathrm{Obs}}^{(i)}\\}}(g(\\theta)) \\stackrel{N \\uparrow \\infty}{\\rightarrow} \\gamma\n\\right]\n\\end{aligned}\n\\]\nDizemos que \\[\n\\frac{1}{N} \\sum \\mathbb{1}_{\\{\\mathrm{IC}_{\\mathrm{Obs}}^{(i)}\\}}(g(\\theta))\n\\] é a cobertura de \\(\\mathrm{IC}(g(\\theta),\\gamma)\\)",
    "crumbs": [
      "Inferência Frequentista",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Intervalos de Confiança - Aprofundamento</span>"
    ]
  },
  {
    "objectID": "intervalos-confianca.html#interpretação-em-termos-de-repetições",
    "href": "intervalos-confianca.html#interpretação-em-termos-de-repetições",
    "title": "38  Intervalos de Confiança - Aprofundamento",
    "section": "",
    "text": "O que dizer sobre \\(\\mathrm{IC}_{\\mathrm{Obs}}\\) em relação a \\(g(\\theta)\\)?\n\n\n\nTemos uma confiança de \\(\\gamma\\cdot 100\\%\\) de que \\(g(\\theta) \\in \\mathrm{IC}_{\\mathrm{Obs}}\\).",
    "crumbs": [
      "Inferência Frequentista",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Intervalos de Confiança - Aprofundamento</span>"
    ]
  },
  {
    "objectID": "intervalos-confianca.html#exemplos",
    "href": "intervalos-confianca.html#exemplos",
    "title": "38  Intervalos de Confiança - Aprofundamento",
    "section": "38.2 Exemplos",
    "text": "38.2 Exemplos\n\n38.2.1 Exemplo Normal\nSeja \\(\\boldsymbol{X}_n\\) a.a. de \\(X \\sim N(\\mu,\\sigma^2), \\theta = (\\mu, \\sigma^2) \\in \\Theta = \\mathbb{R}\\times\\mathbb{R}^+\\). Encontre um IC com coeficiente de confiança \\(\\gamma = 95\\%\\)…\n…para \\(g(\\theta = \\mu)\\)\nSabemos que \\[\n\\bar{X} = \\frac{1}{n} \\sum X_i \\sim N(\\mu, \\sigma^2/n).\n\\] Além disso, \\[\n\\sum \\frac{(X_i - \\bar{X})^2}{\\sigma^2} \\sim \\chi^2_{n-1}\n\\]\nPor definição de t-student, com as V.As das distribuições independentes, \\[\n\\begin{aligned}\n\\frac{N(0,1)}{\\sqrt{\\frac{\\chi^2_k}{k}}} &\\sim t_k  \\\\\n\\Rightarrow\\frac{\\sqrt{n} \\frac{(\\bar{X} - \\mu)}{\\sigma}}{\\sqrt{\\frac{\\sum \\frac{(X_i - \\bar{X})^2}{\\sigma^2}}{n-1}}} &\\sim t_{(n-1)} \\\\\n\\Rightarrow \\frac{\\sqrt{n} (\\bar{X} - \\mu)}{\\sqrt{S^2_{n-1}(\\boldsymbol{X}_n)}} &\\sim t_{(n-1)}\n\\end{aligned}\n\\] logo, podemos sempre encontrar \\(c_{1, \\gamma}, c_{2, \\gamma}\\) tais que \\[\nP_\\theta\\left(c_{2, \\gamma} \\leq \\frac{\\sqrt{n} (\\bar{X} - \\mu)}{\\sqrt{S^2_{n-1}(\\boldsymbol{X}_n)}} \\leq c_{1, \\gamma}\\right) = \\gamma\n\\]\nNote que \\[\nc_{2, \\gamma} \\leq \\frac{\\sqrt{n} (\\bar{X} - \\mu)}{\\sqrt{S^2_{n-1}(\\boldsymbol{X}_n)}} \\leq c_{1, \\gamma} \\iff\n\\bar{X} - c_{2,\\gamma} \\sqrt{\\frac{S^2_{n-1}(\\boldsymbol{X}_n)}{n}} \\leq \\mu \\leq \\bar{X} - c_{1,\\gamma} \\sqrt{\\frac{S^2_{n-1}(\\boldsymbol{X}_n)}{n}}\n\\]\nPortanto, \\[\nP_\\theta\\left(\\bar{X} - c_{2,\\gamma} \\sqrt{\\frac{S^2_{n-1}(\\boldsymbol{X}_n)}{n}} \\leq g(\\theta) \\leq \\bar{X} - c_{1,\\gamma} \\sqrt{\\frac{S^2_{n-1}(\\boldsymbol{X}_n)}{n}}\\right) = \\gamma\n\\]\nPela definição de Intervalo de Confiança, \\[\n\\mathrm{IC}(\\mu,\\gamma) = \\left[\n\\bar{X} - c_{2,\\gamma} \\sqrt{\\frac{S^2_{n-1}(\\boldsymbol{X}_n)}{n}}, \\bar{X} - c_{1,\\gamma} \\sqrt{\\frac{S^2_{n-1}(\\boldsymbol{X}_n)}{n}}\n\\right]\n\\] em que \\[\nS^2_{n-1}(\\boldsymbol{X}_n) = \\frac{1}{n-1} \\sum  (X_i - \\bar{X})^2\n\\] e \\(c_{1,\\gamma}, c_{2,\\gamma}\\) são os quantis obtidos da distribuição t-student com \\(n-1\\) graus de liberdade que satisfaçam \\[\nP_\\theta\\left(\\bar{X} - c_{2,\\gamma} \\sqrt{\\frac{S^2_{n-1}(\\boldsymbol{X}_n)}{n}} \\leq g(\\theta) \\leq \\bar{X} -\nc_{1,\\gamma} \\sqrt{\\frac{S^2_{n-1}(\\boldsymbol{X}_n)}{n}}\\right) = \\gamma\n\\] no caso simétrico (minimiza o IC para distribuições como a Normal), \\(c_{2,\\gamma} = - c_{1,\\gamma}\\). Note que não é possível construir ICs simétricos dessa forma para distribuições estritamente positivas, como a qui-quadrado.",
    "crumbs": [
      "Inferência Frequentista",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Intervalos de Confiança - Aprofundamento</span>"
    ]
  },
  {
    "objectID": "intervalos-confianca.html#sec-quantpivot",
    "href": "intervalos-confianca.html#sec-quantpivot",
    "title": "38  Intervalos de Confiança - Aprofundamento",
    "section": "38.3 Quantidades Pivotais",
    "text": "38.3 Quantidades Pivotais\nDizemos que \\(Q(g(\\theta), \\boldsymbol{X}_n)\\) é uma quantidade pivotal para \\(g(\\theta)\\) se, e somente se,\n\n\\(Q(g(\\theta), \\boldsymbol{X}_n)\\) depende de \\(g(\\theta)\\)\nA distribuição de \\(Q(g(\\theta), \\boldsymbol{X}_n)\\) não depende de “\\(\\theta\\)”\nExistem \\(a_1, a_2\\), que não dependem de \\(g(\\theta)\\), tais que \\(c_1 \\leq Q(g(\\theta),\\boldsymbol{X}_n) \\leq c_2 \\iff a_1 \\leq g(\\theta) \\leq a_2\\)\n\n\n38.3.1 Exemplos\n\\(X \\sim N(\\mu, \\sigma^2)\\)\n\nSe \\(\\sigma^2\\) é conhecido e \\(\\theta = \\mu. g(\\theta) = \\mu\\), então uma quantidade pivotal é dada por \\[\nQ(\\mu, \\boldsymbol{X}_n) = \\sqrt{n}\\frac{\\bar{X} - \\mu}{\\sqrt{\\sigma^2}} \\sim N(0,1)\n\\]\n\n\\[\n\\mathrm{IC}(\\mu,\\gamma) = \\bar{X} \\mp c_{\\gamma} \\sqrt{\\frac{\\sigma^2}{n}}\n\\]\n\nSe \\(\\sigma^2\\) é desconhecido e \\(\\theta = (\\mu, \\sigma^2), g(\\theta) = \\mu\\), então uma quantidade pivotal é dada por \\[\nQ(\\mu, \\boldsymbol{X}_n) = \\sqrt{n}\\frac{\\bar{X}-\\mu}{\\sqrt{S^2_{n-1}(\\boldsymbol{X}_n)}} \\sim t_{(n-1)}\n\\]\n\n\\[\n\\mathrm{IC}(\\mu,\\gamma) = \\bar{X} \\mp c_{\\gamma} \\sqrt{\\frac{S^2_{n-1}(\\boldsymbol{X}_n}{n}}\n\\] essa é também uma quantidade pivotal para 1., mas o contrário não vale.\n\nSe \\(\\mu\\) é conhecido e \\(\\theta = \\sigma^2, g(\\theta) = \\sigma^2\\), então\n\n\\[\nQ(\\sigma^2, \\boldsymbol{X}_n) = \\sum \\frac{(X_i - \\bar{X})^2}{\\sigma^2} \\sim \\chi^2_{n}\n\\]\n\\[\n\\mathrm{IC}(\\sigma^2,\\gamma) = \\left[\\frac{\\sum (X_i - \\mu)^2}{c_{2,\\gamma}}, \\frac{\\sum (X_i - \\mu)^2}{c_{1,\\gamma}}\\right]\n\\]\n\nSe \\(\\mu\\) é desconhecido e \\(\\theta = (\\mu, \\sigma^2), g(\\theta) = \\sigma^2\\), então \\[\nQ(\\sigma^2, \\boldsymbol{X}_n) = \\sum \\frac{(X_i - \\bar{X})}{\\sigma^2} \\sim \\chi^2_{(n-1)}\n\\]\n\n\\[\n\\mathrm{IC}(\\sigma^2,\\gamma) = \\left[\\frac{\\sum (X_i - \\bar{X})^2}{c_{2,\\gamma}}, \\frac{\\sum (X_i - \\bar{X})^2}{c_{1,\\gamma}}\\right]\n\\]\n\n38.3.1.1 Exponencial\nSeja \\(X \\sim \\mathrm{Exp}(\\theta), \\theta &gt; 0\\). Encontre uma quantidade pivotal para \\(\\theta\\).\nNote que \\(\\sum X_i \\sim \\mathrm{Gama}(n,\\theta)\\) com F.G.M. dada por \\[\nM_{\\sum X_i}(t) = \\left(\\frac{\\theta}{\\theta-t}\\right)^n\n\\] note ainda que \\[\n\\begin{aligned}\nM_{\\sum X_i}(t) &= E(\\mathrm{e}^{t \\sum X_i}) =  \\left(\\frac{\\theta}{\\theta-t}\\right)^n \\\\\n\\Rightarrow M_{\\theta \\sum X_i}(t) &= E(\\mathrm{e}^{t\\theta \\sum X_i}) \\\\\n&=M_{\\sum X_i}(t \\theta) = \\left(\\frac{\\theta}{\\theta-\\theta t}\\right)^n = \\left(\\frac{1}{1-t}\\right)^n \\\\\n\\Rightarrow M_{2\\theta\\sum X_i}(t) &= \\left(\\frac{1}{1-2t}\\right)^n \\\\\n\\Rightarrow &2\\theta \\sum X_i \\sim \\chi^2_{(2n)}\n\\end{aligned}\n\\]\nPortanto, \\(Q(\\theta, \\boldsymbol{X}_n) = 2\\theta \\sum X_i\\) é uma quantidade de interesse para \\(\\theta\\)\n\\[\n\\begin{aligned}\nc_{1,\\gamma} &\\leq Q(\\theta, \\boldsymbol{X}_n) \\leq c_{2,\\gamma} \\\\\n\\iff c_{1,\\gamma} &\\leq 2\\theta \\sum X_i \\leq c_{2\\gamma} \\iff \\frac{c_{1,\\gamma}}{2\\sum X_i} \\leq \\theta \\leq \\frac{c_{2,\\gamma}}{2\\sum X_i}\n\\end{aligned}\n\\]\n\n\n38.3.1.2 Uniforme\nSeja \\(X \\sim \\mathrm{Unif}(0, \\theta), \\theta &gt; 0\\). Encontre uma quantidade pivotal para \\(\\theta\\).\nNote que \\(X_{(n)} = \\max \\boldsymbol{X}_n\\) é uma estatística suficiente cuja f.d.p. é dada por \\[\nf_(\\theta)^{\\boldsymbol{X}_{(n)}}(x) = \\frac{n x^{n-1}}{\\theta^n} \\mathrm{1}_{(0,\\theta]}(x)\n\\]\nSeja \\(Y = \\frac{X_{(n)}}{\\theta}\\), então \\[\nf_(\\theta)^{Y}(x) = f_(\\theta)^{\\boldsymbol{X}_{(n)}}(y \\theta) \\cdot |J|\n\\] em que \\(J = \\theta\\) (determinante jacobiano)\n\\[\nf_(\\theta)^{Y}(y) = \\frac{n (y\\theta)^{n-1}}{\\theta^n} \\theta \\mathrm{1}_{(0,\\theta]}(y \\theta) = n y^{n-1} \\mathrm{1}_{(0,1]}(y)\n\\] não depende de “\\(\\theta\\)”! Logo, \\(Q(\\theta, \\boldsymbol{X}_n) = \\frac{\\boldsymbol{X}_{(n)}}{\\theta}\\) é uma quantidade pivotal para \\(\\theta\\).\n\\[\n\\begin{aligned}\n\\frac{\\boldsymbol{X}_{(n)}}{c_{2,\\gamma}} \\leq \\theta \\leq \\frac{\\boldsymbol{X}_{(n)}}{c_{1,\\gamma}}\n\\Rightarrow \\mathrm{IC}(\\theta,\\gamma) = \\left[\n\\frac{\\boldsymbol{X}_{(n)}}{c_{2,\\gamma}}, \\frac{\\boldsymbol{X}_{(n)}}{c_{1,\\gamma}}\n\\right]\n\\end{aligned}\n\\] em que os quantis são obtidos da distribuição de \\(Y\\), nesse caso, \\(Y \\sim \\mathrm{Beta}(n,1)\\):\n\\[\n\\begin{aligned}\n\\int^{c_{1,\\gamma}}_0 ny^{n-1} dy = \\frac{1-\\gamma}{2}&\\ \\ \\ \\int_{c_{2,\\gamma}}^{1} ny^{n-1}dy = \\frac{1-\\gamma}{2} \\\\\n\\Rightarrow \\begin{cases}\ny^n \\rvert_0^{c_{1,\\gamma}} = \\frac{1-\\gamma}{2} \\\\\ny^n \\rvert^1_{c_{2,\\gamma}} = \\frac{1-\\gamma}{2} \\\\\n\\end{cases}\n\\Rightarrow c_{1,\\gamma} &= \\left(\\frac{1-\\gamma}{2}\\right)^{1/2}\\ \\ \\ \\ c_{2,\\gamma} = \\left(\\frac{1+\\gamma}{2}\\right)^{1/2}\n\\end{aligned}\n\\]\n\n\n\n\n\n\nQuantis que minimizam a amplitude do IC\n\n\n\nSeja \\(Q(g(\\theta), \\boldsymbol{X}_n)\\) uma quantidade pivotal com função densidade de probabilidade \\(f\\).\n\\(c_{1,\\gamma}, c_{2,\\gamma}\\) devem ser obtidos \\[\n\\int_{c_{1,\\gamma}}^{c_{2,\\gamma}} f(x) dx = \\gamma\n\\tag{38.1}\\]\nNote que em geral infinitas combinações desses quantis satisfazem (38.1). Podemos usar o par que satisfaz \\[\n\\int^{c_{1,\\gamma}}_{-\\infty} f(y) dy = \\frac{1-\\gamma}{2}\\ \\ \\mathrm{e} \\ \\ \\int_{c_{2,\\gamma}}^{\\infty} f(y)dy = \\frac{1-\\gamma}{2}\n\\]\nEsse método produz um intervalo de confiança simétrico, não necessariamente o de menor amplitude, mas é mais fácil de encontrar. O intervalo de confiança com menor amplitude com quantis que satisfaçam (38.1) é obtido minimizando \\(|c_{2,\\gamma} - c_{1,\\gamma}|\\) sujeito a (38.1).\nSe \\(f\\) for unimodal e bicaudal, pode-se demonstrar que \\(c_{1,\\gamma}, c_2{\\gamma}\\) que produzem amplitude mínima e satisfazem (38.1) são tais que \\[\nf(c_{1,\\gamma}) = f(c_{2,\\gamma})\n\\] ou seja, tem mesma densidade.\n\n\n\nusing Distributions, Random, StatsBase, LaTeXStrings\n\nRandom.seed!(8)\n\ntheta0 = 4\nn = 10\nMC = 10000\n\nI1 = []\nI2 = []\nfor _ in 1:MC\n  d = Exponential(1/theta0) # Parâmetro média =&gt; 1/theta parâmetro taxa\n  x = rand(d,n)\n\n  # Construindo um IC com 95% de confiança\n  gamma = 0.95\n  quiquadrado = Chisq(2*n)\n  c1 = quantile(quiquadrado, (1-gamma)/2)\n  c2 = quantile(quiquadrado, gamma + (1-gamma)/2)\n  push!(I1, round(c1/(2*sum(x)), digits=4))\n  push!(I2, round(c2/(2*sum(x)), digits=4))\nend\n\nacertos = [I1 .&lt;= theta0 .&lt;= I2]\ndisplay(L\"\\mathrm{IC}_{\\mathrm{Obs (1)}}(\\theta,0.95)=[%$(I1[1]), %$(I2[1])]\")\ndisplay(L\"\\text{ICs que contém}\\ \\theta: %$((sum(acertos[1]))/MC * 100)\\%\")\n\n\\(\\mathrm{IC}_{\\mathrm{Obs (1)}}(\\theta,0.95)=[2.7345, 9.7424]\\)\n\n\n\\(\\text{ICs que contém}\\ \\theta: 94.97\\%\\)\n\n\n\n\n\n38.3.2 Quantidades pivotais aproximadas ou assintóticas\nDizemos que \\(Q(g(\\theta), \\boldsymbol{X}_n)\\) é uma quantidade pivotal aproximada ou assintótica se, e somente se\n\n\\(Q(g(\\theta), \\boldsymbol{X}_n)\\) depende de \\(g(\\theta)\\);\nA distribuição assintótica de \\(Q(g(\\theta), \\boldsymbol{X}_n)\\) não depende de \\(g(\\theta)\\);\nExistem \\(a_1, a_2\\), que não dependem de \\(g(\\theta)\\), tais que \\(c_1 \\leq Q(g(\\theta),\\boldsymbol{X}_n) \\leq c_2 \\iff a_1 \\leq g(\\theta) \\leq a_2\\). Esses valores dependem apenas de \\(\\boldsymbol{X}_n\\).\n\nPodemos usar o TLC para estimadores:\nSe \\(T(\\boldsymbol{X}_n)\\) for um estimador para \\(\\theta\\) assintoticamente normal, então\n\\[\n\\sqrt{n} (T(\\boldsymbol{X}_n) - \\theta)  \\stackrel{\\mathcal{D}}{\\rightarrow} N_p(0, V_\\theta), \\forall \\theta \\in \\Theta.\n\\] em que \\(V_\\theta\\) é uma matriz positiva definida. Para \\(p=1\\), \\[\n\\sqrt{n} (T(\\boldsymbol{X}_n) - \\theta)  \\stackrel{\\mathcal{D}}{\\rightarrow} N_1(0, V_\\theta), \\forall \\theta \\in \\Theta.\n\\] em que \\(V_\\theta &gt; 0\\).\nSe \\(g: \\Theta \\rightarrow \\mathbb{R}\\) for uma função tal que \\(g'(\\theta) \\neq 0\\) \\(g'(\\theta)\\) é contínua, então, \\[\n\\sqrt{n} (g(T(\\boldsymbol{X}_n)) - g(\\theta))  \\stackrel{\\mathcal{D}}{\\rightarrow} N_1(0, g'(\\theta)^2V_\\theta), \\forall \\theta \\in \\Theta.\n\\]\nAlém disso,\n\n\\[\n\\frac{\\sqrt{n} (g(T(\\boldsymbol{X}_n)) - g(\\theta))}{\\sqrt{g'(\\theta)^{-2}V_\\theta}}  \\stackrel{\\mathcal{D}}{\\rightarrow} N_1(0, 1), \\forall \\theta \\in \\Theta.\n\\]\nPelo teorema de Slutsky \\[\n\\frac{\\sqrt{n} (g(T(\\boldsymbol{X}_n)) - g(\\theta))}{\\sqrt{g'(T(\\boldsymbol{X}_n))^{-2}V_{T(\\boldsymbol{X}_n)}}}  \\stackrel{\\mathcal{D}}{\\rightarrow} N_1(0, 1), \\forall \\theta \\in \\Theta.\n\\]\n\nOu seja, \\[\nQ(g(\\theta), \\boldsymbol{X}_n) = \\frac{\\sqrt{n} (g(T(\\boldsymbol{X}_n)) - g(\\theta))}{\\sqrt{g'(T(\\boldsymbol{X}_n))^{-2}V_{T(\\boldsymbol{X}_n)}}}\n\\] é uma quantidade pivotal aproximada para \\(g(\\theta)\\). Note que, com \\(T(\\boldsymbol{X}_n) = \\hat(\\theta)\\), \\[\n\\begin{aligned}\n&c_1 \\leq Q(g(\\theta), \\boldsymbol{X}_n) \\leq c_2 \\\\\n\\iff& c_1 \\leq \\frac{\\sqrt{n} (g(T(\\boldsymbol{X}_n)) - g(\\theta))}{\\sqrt{g'(T(\\boldsymbol{X}_n))^{-2}V_{T(\\boldsymbol{X}_n)}}} \\leq c_2 \\\\\n\\iff& c_1 \\sqrt{\\frac{g'(\\hat\\theta)^2}{n} V_{\\hat\\theta}} \\leq g(\\hat\\theta) - g(\\theta) \\leq c_2\\sqrt{\\frac{g'(\\hat\\theta)^2}{n} V_{\\hat\\theta}} \\\\\n\\iff& g(\\hat\\theta) - c_2 \\sqrt{\\frac{g'(\\hat\\theta)^2}{n} V_{\\hat\\theta}} \\leq g(\\theta) \\leq g(\\hat\\theta) - c_1\\sqrt{\\frac{g'(\\hat\\theta)^2}{n} V_{\\hat\\theta}} \\\\\n\\end{aligned}\n\\] Tomando \\(c_1 = -c_2\\), pois a distribuição assintótica é normal, temos \\[\n\\mathrm{IC}^a(g(\\theta),\\gamma) = \\left[\ng(\\hat\\theta) - c_2 \\sqrt{\\frac{g'(\\hat\\theta)^2}{n} V_{\\hat\\theta}}, g(\\hat\\theta) + c_2 \\sqrt{\\frac{g'(\\hat\\theta)^2}{n} V_{\\hat\\theta}}\n\\right]\n\\] em que \\(c_2\\) é obtido dos quantis da normal padrão tal que \\[\nP(-c_2 \\leq N(0,1) \\leq c_2) = \\gamma\n\\]\n\n\n\n\n\n\nErro padrão\n\n\n\nA quantidade \\[\n\\sqrt{\\frac{g'(\\hat\\theta)^2}{n} V_{\\hat\\theta}}\n\\] é o erro-padrão do estimador (seu desvio padrão).\n\n\nVamos conferir por simulações de monte carlo e o método de Newton-Raphson\na-) para θ\nb-) para \\(g(\\theta) = P(X &lt; 950) =&gt; g'(\\theta) = f_\\theta(950)\\)\nc-) para g(θ) = ln f_θ(x) g’(θ) = - ψ_1(θ) + ln(θ) - 1/θ\nd-) para g(θ) = f_(x)\n\nusing SpecialFunctions, Distributions, Random, LaTeXStrings\n# Modelo Gama(θ, 1)\n# IC assintótico\n# Calcule o IC\n#a-) para θ\n#b-) para g(θ) = P(X &lt; 950) =&gt; g'(θ) = f_θ(950)\n#c-) para g_x(θ) = ln f_θ(x) g'(θ) = - ψ_1(θ) + ln(θ) - 1/θ. x = θ\n#d-) para g_x(θ) = f_\\theta(x). x = θ\n\n\n# Sabemos que θ.MV ~a~ N(θ, I_n(θ)^-1)\n# =&gt; IC^a(θ,γ) = θ.MV ∓ c_2 * √(I_1(θ))\n\nRandom.seed!(13)\n\nfunction newton_raphson(x)\n\n  theta::Vector{Float64} = []\n  append!(theta, mean(x)) # Chute inicial = média\n  erromax = 10^(-5)\n  erro = Inf\n  i = 1\n  # iteracoesMax = 6 # Podemos também definir apenas um erro máximo\n  while erro &gt; erromax # && i &lt; iteracoesMax\n    append!(theta, theta[i] - (sum(log.(x)) - n * digamma(theta[i]))/\n            (-n*trigamma(theta[i])))\n    erro = abs(theta[i+1] - theta[i])\n    # println(\"Erro na iteração $i: $erro\")\n    i += 1\n  end\n  # println(\"Theta final: $(theta[length(theta)])\")\n  # println(\"Total de iterações: $i\")\n  return theta[end]\nend\n\n# Resolução do item a\nfunction monte_carlo_a(M, γ, n, theta0)\n  d = Gamma(theta0, 1)\n  function mc()\n    x = rand(d, n)\n    EMV = newton_raphson(x)\n    c2 = quantile(Normal(), γ + (1-γ)/2)\n    I1 = EMV - c2 * sqrt(1/(n*trigamma(EMV)))\n    I2 = EMV + c2 * sqrt(1/(n*trigamma(EMV)))\n    return I1, I2\n  end\n\n  inferiores = []; superiores = [] \n  for _ in 1:M\n    intervalo = mc()\n    push!(inferiores, intervalo[1])\n    push!(superiores, intervalo[2])\n  end\n\n  acertos = inferiores .&lt;= theta0 .&lt;= superiores\n  return mean(acertos)\n\nend\n\nRodando o código para o item a, temos\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.95, n = 100, \\theta_0 = 100:\\ 95.07\\%\\)\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.99, n = 100, \\theta_0 = 100:\\ 99.03\\%\\)\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.99, n = 5, \\theta_0 = 75:\\ 98.91\\%\\)\n\n\nPara o item b,\n\n# Resolução do item b\nfunction monte_carlo_b(M, γ, n, theta0)\n  d = Gamma(theta0, 1)\n  g(a) = cdf(Gamma(a, 1), 950)\n  g1(a) = pdf(Gamma(a,1), 950)\n  function mc()\n    x = rand(d, n)\n    EMV = newton_raphson(x)\n    c2 = quantile(Normal(), γ + (1-γ)/2)\n    I1 = g(EMV) - c2 * sqrt(g1(EMV)^2/(n*trigamma(EMV)))\n    I2 = g(EMV) + c2 * sqrt(g1(EMV)^2/(n*trigamma(EMV)))\n    return I1, I2\n  end\n\n  inferiores = []; superiores = [] \n  for _ in 1:M\n    intervalo = mc()\n    push!(inferiores, intervalo[1])\n    push!(superiores, intervalo[2])\n  end\n\n  acertos = inferiores .&lt;= g(theta0) .&lt;= superiores\n  return mean(acertos) \n\nend\n\nRodando o código para o item b, temos\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.95, n = 100, \\theta_0 = 1000:\\ 94.88\\%\\)\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.99, n = 100, \\theta_0 = 951:\\ 98.61\\%\\)\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.99, n = 5, \\theta_0 = 951:\\ 94.67\\%\\)\n\n\nPara o item c, precisaremos calcurar as derivadas: \\[\n\\begin{aligned}\ng(\\theta) &= \\ln f_\\theta(\\theta) = - \\ln \\Gamma(\\theta) + (\\theta-1) \\ln (\\theta) - \\theta \\\\\n\\Rightarrow g'(\\theta) &= -\\psi_1(\\theta) + \\ln(\\theta) + \\frac{\\theta -1}{\\theta} - 1 \\\\\n&= -\\psi_1(\\theta) + \\ln(\\theta) - \\frac{-1}{\\theta} = g1(\\theta)\n\\end{aligned}\n\\]\n\n# Resolução do item c\nfunction monte_carlo_c(M, γ, n, theta0)\n  d = Gamma(theta0, 1)\n  g(a) =  log(pdf(Gamma(a, 1), a))\n  g1(a) = -digamma(a) + log(a) - 1/a\n  function mc()\n    x = rand(d, n)\n    EMV = newton_raphson(x)\n    c2 = quantile(Normal(), γ + (1-γ)/2)\n    I1 = g(EMV) - c2 * sqrt(g1(EMV)^2/(n*trigamma(EMV)))\n    I2 = g(EMV) + c2 * sqrt(g1(EMV)^2/(n*trigamma(EMV)))\n    return I1, I2\n  end\n\n  inferiores = []; superiores = [] \n  for _ in 1:M\n    intervalo = mc()\n    push!(inferiores, intervalo[1])\n    push!(superiores, intervalo[2])\n  end\n  acertos = inferiores .&lt;= g(theta0) .&lt;= superiores\n  return mean(acertos) \nend\n\nRodando o código para o item c, temos\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.95, n = 100, \\theta_0 = 100:\\ 94.77\\%\\)\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.99, n = 100, \\theta_0 = 100:\\ 99.06\\%\\)\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.99, n = 5, \\theta_0 = 75:\\ 98.97\\%\\)\n\n\nPara o item d, note que \\[\ng'(\\theta) = \\mathrm{e}^{\\ln f_\\theta(x)} (-\\psi_1(\\theta) + \\ln(\\theta) - 1/\\theta)\n\\]\n\n# Resolução do item d\nfunction monte_carlo_d(M, γ, n, theta0)\n  d = Gamma(theta0, 1)\n  g(a) = exp(log(pdf(Gamma(a, 1), a))) # usado a expp(log), poderia usar direto\n  g1(a) = exp(log(pdf(Gamma(a,1), a))) * (-digamma(a) + log(a) - 1/a)\n  function mc()\n    x = rand(d, n)\n    EMV = newton_raphson(x)\n    c2 = quantile(Normal(), γ + (1-γ)/2)\n    I1 = g(EMV) - c2 * sqrt(g1(EMV)^2/(n*trigamma(EMV)))\n    I2 = g(EMV) + c2 * sqrt(g1(EMV)^2/(n*trigamma(EMV)))\n    return I1, I2\n  end\n\n  inferiores = []; superiores = [] \n  for _ in 1:M\n    intervalo = mc()\n    push!(inferiores, intervalo[1])\n    push!(superiores, intervalo[2])\n  end\n  acertos = inferiores .&lt;= g(theta0) .&lt;= superiores\n  return mean(acertos) \nend\n\nRodando o código para o item d, temos\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.95, n = 100, \\theta_0 = 100:\\ 95.28\\%\\)\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.99, n = 100, \\theta_0 = 100:\\ 99.02\\%\\)\n\n\n\\(\\text{Confiança para } 10000 \\text{ simulações com alvo } 0.99, n = 5, \\theta_0 = 75:\\ 98.83999999999999\\%\\)\n\n\n\n38.3.2.1 Comparação entre o exato e aproximado\n\nusing Plots, LaTeXStrings, Distributions, StatsBase, Random\n\nfunction monte_carlo_realxaprox()\n  theta0 = 10\n  M = 100_000\n  nn = 100\n\n  γ = 0.95\n\n  g(a) = a\n  g1(a) = 1\n\n  w = 0\n  cober = zeros(nn)\n  cobera = zeros(nn)\n  for n in 1:nn\n    w += 1\n    I1 = zeros(M)\n    Ia1 = zeros(M)\n    I2 = zeros(M)\n    Ia2 = zeros(M)\n\n    for i in 1:M\n      x = rand(Exponential(1/theta0), n)\n      c1 = quantile(Chisq(2n), (1-γ)/2)\n      c2 = quantile(Chisq(2n), γ + (1-γ)/2)\n      I1[i] = c1/(2*sum(x))\n      I2[i] = c2/(2*sum(x))\n\n      ca2 = quantile(Normal(), γ + (1-γ)/2)\n      EMV =  1/mean(x)\n      Ia1[i] = g(EMV) - ca2 * sqrt(g1(EMV)^2 * EMV^2 /n)\n      Ia2[i] = g(EMV) + ca2 * sqrt(g1(EMV)^2 * EMV^2 /n)\n    end\n    cober[w] = mean(I1 .&lt;= theta0 .&lt;= I2)\n    cobera[w] = mean(Ia1 .&lt;= g(theta0) .&lt;= Ia2)\n  end\n  preal = scatter(1:10:100, cober, color=\"blue\",\n                  label=\"Cobertura do IC real observado\",\n                  title=\"Comparação entre ICs: Cobertura\",\n                  ylims=(γ-0.1, γ+0.1),\n                  xlabel=\"Cobertura\",\n                  ylabel=L\"n\")\n  scatter!(1:10:100, cobera, color=\"red\", label=\"Cobertura IC aproximado\")\n  hline!([γ], label=L\"\\gamma\")\n  return preal\nend\n\n\n\n\nsetHighDpiScaleFactorRoundingPolicy must be called before creating the QGuiApplication instance\nqt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\nThis application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n\nAvailable platform plugins are: linuxfb, xcb, vkkhrdisplay, eglfs, minimalegl, vnc, minimal, offscreen.\n\nconnect: Connection refused\nGKS: can't connect to GKS socket application\n\nGKS: Open failed in routine OPEN_WS\nGKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS\nsetHighDpiScaleFactorRoundingPolicy must be called before creating the QGuiApplication instance\nqt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\nThis application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n\nAvailable platform plugins are: linuxfb, xcb, vkkhrdisplay, eglfs, minimalegl, vnc, minimal, offscreen.\n\nconnect: Connection refused\nGKS: can't connect to GKS socket application\n\nGKS: Open failed in routine OPEN_WS\nGKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS\nsetHighDpiScaleFactorRoundingPolicy must be called before creating the QGuiApplication instance\nqt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\nThis application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n\nAvailable platform plugins are: linuxfb, xcb, vkkhrdisplay, eglfs, minimalegl, vnc, minimal, offscreen.\n\nconnect: Connection refused\nGKS: can't connect to GKS socket application\n\nGKS: Open failed in routine OPEN_WS\nGKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS\nsetHighDpiScaleFactorRoundingPolicy must be called before creating the QGuiApplication instance\nqt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\nThis application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n\nAvailable platform plugins are: linuxfb, xcb, vkkhrdisplay, eglfs, minimalegl, vnc, minimal, offscreen.\n\nconnect: Connection refused\nGKS: can't connect to GKS socket application\n\nGKS: Open failed in routine OPEN_WS\nGKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n38.3.2.2 Exemplo poisson\nNote que0 \\[\n\\begin{aligned}\n\\hat{\\theta}_{\\mathrm{MV}}(\\boldsymbol{X}_n) &= \\bar{X} \\\\\n\\sqrt{n}\\frac{\\hat{\\theta}_{\\mathrm{MV}}(\\boldsymbol{X}_n) - \\theta}{\\sqrt{\\theta}} &\\stackrel{\\mathcal{D}}{\\rightarrow} N(0,1) \\\\\n\\sqrt{n}\\frac{\\hat{\\theta}_{\\mathrm{MV}}(\\boldsymbol{X}_n) - \\theta}{\\sqrt{\\hat{\\theta}_{\\mathrm{MV}}(\\boldsymbol{X}_n)}} &\\stackrel{\\mathcal{D}}{\\rightarrow} N(0,1) \\\\\n\\end{aligned}\n\\]\n\nfunction monte_carlo_poiss()\n  theta0 = 10\n  d = Poisson(theta0)\n  g(a) = a\n  g1(a) = 1\n  nn = 1000\n  amplitude = zeros(nn)\n  cober = zeros(nn)\n  M = 10_000\n  for n in nn\n    I1 = zeros(M)\n    I2 = zeros(M)\n    for i in 1:M\n      x = rand(d, n)\n      EMV = mean(x)\n      c2 = quantile(Normal(), γ + (1-γ)/2)\n      I1[i] = EMV - c2 * sqrt(g1(EMV)^2 * EMV/n)\n      I2[i] = EMV + c2 * sqrt(g1(EMV)^2 * EMV/n)\n    end\n    amplitude[n] = mean(I2 .- I1)\n    cober[n] = mean(I1 .&lt;= g(theta0) .&lt;= I2)\n  end\n  amp = scatter(10:100:1000, amplitude)\n  cob = scatter(10:100:1000, cober)\n  plt = plot(amp, cob)\n  return plt\nend\n\n\n\nsetHighDpiScaleFactorRoundingPolicy must be called before creating the QGuiApplication instance\nqt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\nThis application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n\nAvailable platform plugins are: linuxfb, xcb, vkkhrdisplay, eglfs, minimalegl, vnc, minimal, offscreen.\n\nconnect: Connection refused\nGKS: can't connect to GKS socket application\n\nGKS: Open failed in routine OPEN_WS\nGKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS\nsetHighDpiScaleFactorRoundingPolicy must be called before creating the QGuiApplication instance\nqt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\nThis application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n\nAvailable platform plugins are: linuxfb, xcb, vkkhrdisplay, eglfs, minimalegl, vnc, minimal, offscreen.\n\nconnect: Connection refused\nGKS: can't connect to GKS socket application\n\nGKS: Open failed in routine OPEN_WS\nGKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS\nsetHighDpiScaleFactorRoundingPolicy must be called before creating the QGuiApplication instance\nqt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\nThis application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n\nAvailable platform plugins are: linuxfb, xcb, vkkhrdisplay, eglfs, minimalegl, vnc, minimal, offscreen.\n\nconnect: Connection refused\nGKS: can't connect to GKS socket application\n\nGKS: Open failed in routine OPEN_WS\nGKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS\nsetHighDpiScaleFactorRoundingPolicy must be called before creating the QGuiApplication instance\nqt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\nThis application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n\nAvailable platform plugins are: linuxfb, xcb, vkkhrdisplay, eglfs, minimalegl, vnc, minimal, offscreen.\n\nconnect: Connection refused\nGKS: can't connect to GKS socket application\n\nGKS: Open failed in routine OPEN_WS\nGKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS",
    "crumbs": [
      "Inferência Frequentista",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Intervalos de Confiança - Aprofundamento</span>"
    ]
  }
]
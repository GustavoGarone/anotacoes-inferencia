# Estimador de Máxima Verossimilhança (EMV) - Aprofundamento

Seja $\mathcal{L}_{\boldsymbol{x}_n}(\theta)$ a [função de verossimilhança](funcao-verossimilhanca.qmd) de um [modelo estatístico](modelo-estatistico.qmd).
Dizemos que $\hat{\theta}_{\mathrm{MV}}(\boldsymbol{X}_n)$ é um [estimador](estimadores.qmd) de máxima verossimilhança se, e somente se,
$$
\mathcal{L}_{\boldsymbol{x}_n}(\hat{\theta}_{\mathrm{MV}}(\boldsymbol{x}_n)) \geq \mathcal{L}_{\boldsymbol{x}_n}(\theta),\ \mathrm{q.c.}\ \forall \theta \in \Theta.
$$
em que $\boldsymbol{x}_n$ representa uma possível [amostra observada](populacao-e-amostra.qmd#sec-ao).

::: {.callout-note title="Observação"}
$\hat{\theta}_{\mathrm{MV}}(\boldsymbol{X}_n)$ é um [estimador](estimadores.qmd) (quase certamente, ele é único).

$\hat{\theta}_{\mathrm{MV}}(\boldsymbol{x}_n)$ é uma [estimativa](estimadores.qmd#sec-estimativa).
:::

## Exemplos

### Exemplo Uniforme

Seja $\boldsymbol{X}_n$ [a.a.](populacao-e-amostra.qmd#sec-aa) de $X\sim \mathrm{U}(0,\theta), \theta > 0$. Encontre o EMV.

#### Resposta

A função de verossimilhança é dada por
$$
\mathcal{L}_{\boldsymbol{x}_n}(\theta) \stackrel{\mathrm{iid}}{=} \prod^n_{i=1} f_\theta(x_i) = \prod\left\{\frac{1}{\theta} \mathbb{1}_{(0,\theta]}(x_i)\right\}
= \frac{1}{\theta^n} \prod \mathbb{1}_{(0,\theta]}(x_i)
$$

Note que
$$
\prod \mathbb{1}_{(0,\theta]}(x_i) = 1 \iff \mathbb{1}_{[0,\infty)}(\min\boldsymbol{x}_n) \mathbb{1}_{(-\infty,\theta]}(\max\boldsymbol{x}_n) = 1
$$
Como $0 < \max \boldsymbol{x}_n \leq \theta < \infty$,
$$
\mathcal{L}_{\boldsymbol{x}_n}(\theta) \frac{1}{\theta^n} \mathbb{1}_{[0,\infty)}(\min \boldsymbol{x}_n) \mathbb{1}_{[\max \boldsymbol{x}_n, \infty)}
$$

Note que a função é *estritamente decrescente* para qualquer valor de $\theta \geq \max \boldsymbol{x}_n$ e vale $0$ para $\theta \leq \max \boldsymbol{x}_n$,
temos que $\theta = \max\boldsymbol{x}_n$  é o ponto que maximiza a função de verossilhança, logo,
$$
\hat{\theta}_{\mathrm{MV}}(\boldsymbol{X}_n) = \max \boldsymbol{X}_n
$$
é o estimador de máxima verossimilhança.

### Exemplo Beta

Seja $\boldsymbol{X}_n$ a.a. de $X\sim f_\theta, \theta \in \Theta = (0,\infty)$ tal que
$$
f_\theta(x) = \left\{\begin{array}{ll}
\theta x^{\theta-1}, x \in (0,1) \\
0, \mathrm{c.c}
\end{array}\right.
$$

Encontre o EMV para "$\theta$".

#### Resposta

A função de verossimilhança é
$$
\begin{aligned}
\mathcal{L}_{\boldsymbol{x}_n}(\theta) &\stackrel{\mathrm{i.i.d.}}{=} \prod^n_{i=1} f_\theta(x_i) \\
&= \prod \left\{\theta x_i^{\theta-1}\right\} \\
&= \theta^n\left(\prod x_i\right)^{\theta-1}
\end{aligned}
$$

Como $\mathcal{L}_{\boldsymbol{x}_n}$ é positiva $\forall \theta \in \Theta$, temos que,
$$
\ln\mathcal{L}_{\boldsymbol{x}_n}(\theta) = n \ln \theta + (\theta-1) \sum \ln x_i
$$

Ademais, $\ln(\cdot)$ é uma função estritamente crescente. Portanto, o valor que maximiza $\mathcal{L}_{\boldsymbol{x}_n}(\cdot)$ é
o mesmo que maximiza $\ln \mathcal{L}_{\boldsymbol{x}_n}(\cdot)$.

Encontramos os pontos críticos de $\ln \mathcal{L}_{\boldsymbol{X}_n}(\theta)$
$$
\begin{aligned}
&\frac{d\ln \mathcal{L}_{\boldsymbol{x}_n}(\theta)}{d\theta} = 0 \\
&\Rightarrow \frac{n}{\theta} + \sum \ln x_i = 0 \\
&\iff \hat{\theta} = - \frac{n}{\sum \ln x_i}\ \text{é um ponto crítico.}
\end{aligned}
$$

Para a segunda derivada,
$$
\frac{d^2\ln \mathcal{L}_{\boldsymbol{x}_n}(\theta)}{d\theta^2} = -\frac{n}{\theta^2} < 0, \forall \theta \in \Theta.
$$

Logo,
$$
\hat{\theta}_{\mathrm{MV}}(\boldsymbol{X}_n) = - \frac{n}{\sum \ln x_i}
$$
é o EMV.

## Caso Geral

Seja $\boldsymbol{X}_n$ a.a. de $X \sim f_\theta, \theta \in \Theta \subseteq \mathbb{R}^P.$ Considere $\boldsymbol{x}_n$ uma possível amostra
observada e considere as [Condições $C_1:C_4$](escore.qmd#sec-condicoes) válidas. Então, o EMV pode ser obtido igualando
a [função escore](escore.qmd) a zero. Ou seja,

$$
U_n(\boldsymbol{X}_n,\hat{\theta}_{\mathrm{MV}}(\boldsymbol{X}_n))
$$
em que
$$
U_n(\boldsymbol{x}_n,\theta) = \frac{\partial \ln \mathcal{L}_{\boldsymbol{x}_n}(\theta)}{\partial \theta}
$$
desde que 
$$
\left.\frac{\partial U_n(\boldsymbol{x}_n,\theta)}{\partial \theta^T}\right\rvert_{\theta = \hat{\theta}_{\mathrm{MV}}(\boldsymbol{x}_n)}
$$
é negativa definida para quase todo $\boldsymbol{x}_n$. Ou seja,
$$
\left.\frac{\partial U_n(\boldsymbol{x}_n,\theta)}{\partial \theta^T}\right\rvert_{\theta = \hat{\theta}_{\mathrm{MV}}(\boldsymbol{x}_n)}
=  \left.\frac{\partial^2 \ln \mathcal{L}_{\boldsymbol{x}_n}}{\partial \theta \partial \theta^T}\right\rvert_{\theta = \hat{\theta}_{\mathrm{MV}}(\boldsymbol{x}_n)}
$$
é negativa definida.

::: {.callout-note title="Matrizes positivas definidas"}
Dizemos que $A$ é positiva definida se, e somente se,
$$
x^TAx > 0, \forall x \in \mathbb{R}^P\setminus \{\boldsymbol{0}\}
$$

Teorema

$A$ simétrica ($A$ = $A^T$) é positiva definida se, e somente se, todos seus autovalores são positivos.
:::

::: {.callout-note title="Matrizes negativas definidas"}
Dizemos que $A$ é positiva definida se, e somente se,
$$
x^TAx < 0, \forall x \in \mathbb{R}^P \setminus \{\boldsymbol{0}\}
$$

Teorema

$A$ simétrica ($A$ = $A^T$) é negativa definida se, e somente se, todos seus autovalores são negativos.
:::

::: {.callout-tip}
Uma matriz $A$ de dimensões $2\times 2$ é dita positiva(negativa) definida se, e somente se, os elementos da diagonal são
positivos(negativos) e o determinante de $A$ é positivo.
:::

### Exemplos

#### Exemplo Normal {#sec-exnorm}
Seja $\boldsymbol{X}_n$ a.a. de $X \sim \mathrm{N}(\mu,\sigma^2), \theta = (\mu, \sigma^2) \in \Theta = \mathbb{R}\times\mathbb{R}_+$

##### Resposta

A função de verossimilhança é
$$
\begin{aligned}
\mathcal{L}_{\boldsymbol{x}_n}(\theta) &= \frac{1}{(\sqrt{2 \pi \sigma^2})^n} \mathrm{e}^{-\frac{1}{2\sigma^2} \sum (x_i - \mu)^2} \\
\Rightarrow \ln \mathcal{L}_{\boldsymbol{x}_n}(\theta) &= -\frac{n}{2} \ln(2\pi) - \frac{n}{2} \ln(\sigma^2) - \frac{1}{2\sigma^2} \sum (x_i - \mu)^2.
\end{aligned}
$$

Logo,
$$
U_n(\boldsymbol{x}_n,\theta) = \frac{\partial \ln }{\partial \theta} \mathcal{L}_{\boldsymbol{x}_n}(\theta) = \left(\begin{array}{cc}
\frac{\partial \ln }{\partial \mu} \mathcal{L}_{\boldsymbol{x}_n}(\theta) \\
\frac{\partial \ln }{\partial \sigma^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta)
\end{array}\right)
$$
em que
$$
\frac{\partial \ln }{\partial \mu} \mathcal{L}_{\boldsymbol{x}_n}(\theta) = -\frac{1}{2\sigma^2} \sum 2(x_i-\mu)(-1) = \frac{1}{\sigma^2} \sum (x_i - \mu)
$$
e
$$
\frac{\partial \ln }{\partial \sigma^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta) = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4} \sum (x_i-\mu)^2
$$

Logo,
$$
\begin{aligned}
U_n(\boldsymbol{x}_n,\theta) &= 0 \\
\iff &\left\{\begin{array}{l}
\frac{\partial \ln }{\partial \mu} \mathcal{L}_{\boldsymbol{x}_n}(\theta) = \frac{1}{\sigma^2} \sum (x_i - \mu) &= 0 \\
\frac{\partial \ln }{\partial \sigma^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta) = -\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4} \sum (x_i-\mu)^2 &= 0
\end{array}\right. \\
\iff &\left\{\begin{array}{l}
\sum x_i -n \mu= 0 \\
-n + \frac{1}{\sigma^2} \sum (x_i - \mu)^2 = 0
\end{array}\right. \\
\iff &\left\{\begin{array}{l}
\mu = \sum \frac{x_i}{n} = 0 \\
\sigma^2 = \sum \frac{(x_i-\mu)^2}{n}
\end{array}\right. \\
\Rightarrow &\left\{\begin{array}{l}
\hat{\mu} = \bar{x} \\
\hat{\sigma^2} = \frac{1}{n} \sum (x_i - \bar{x})^2
\end{array}\right.
\end{aligned}
$$

Ou seja, $\hat{\theta} = (\hat{\mu}, \hat{\sigma^2})$ é o ponto crítico de $\ln \mathcal{L}_{\boldsymbol{x}_n}(\theta)$.

Continuando,
$$
\begin{aligned}
\frac{\partial^2 \ln}{\partial \theta \partial \theta^T} \mathcal{L}_{\boldsymbol{x}_n}(\theta) &=
\frac{\partial U_n(\boldsymbol{x}_n,\theta)}{\partial \theta^T} \\
&= \frac{\partial}{\partial \theta^T}
\left[
\begin{array}{c}
\frac{\partial \ln}{\partial \mu} \mathcal{L}_{\boldsymbol{x}_n}(\theta) \\
\frac{\partial \ln}{\partial \sigma^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta)
\end{array}\right] \\
&= \left[
\begin{array}{cc}
\frac{\partial^2 \ln}{\partial \mu^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta) &
\frac{\partial^2 \ln}{\partial \mu \partial \sigma^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta) \\
\frac{\partial^2 \ln}{\partial \mu \partial \sigma^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta) &
\frac{\partial^2 \ln}{\partial (\sigma^2)^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta) \\
\end{array}\right] \\
\Rightarrow  \frac{\partial^2 \ln}{\partial \mu^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta) &= -\frac{n}{\sigma^2} \\
\frac{\partial^2 \ln}{\partial \mu \partial \sigma^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta) &= -\frac{1}{\sigma^4} \sum (x_i - \mu) \\
\frac{\partial^2 \ln}{\partial (\sigma^2)^2} \mathcal{L}_{\boldsymbol{x}_n}(\theta) &= \frac{n}{2\sigma^4} + \frac{1}{2} \sum (x_i - \mu)^2 \cdot \frac{\partial (\sigma^2)^2}{\partial \sigma^2} \\
&= \frac{n}{2\sigma^4} - \sum \frac{(x_i - \mu)^2}{\sigma^6} \\
\Rightarrow 
\left.\frac{\partial^2 \ln}{\partial \theta \partial \theta^T} \mathcal{L}_{\boldsymbol{x}_n}(\theta)\right\rvert_{\theta = \hat{\theta}} &=
\left[
\begin{array}{cc}
-\frac{n}{\hat{\sigma}^2} & -\frac{1}{(\hat{\sigma}^2)^2} \sum (x_i - \bar{x}) \\
-\frac{1}{(\hat{\sigma}^2)^2} \sum (x_i - \bar{x}) & \frac{n}{2(\hat{\sigma}^2)^2} - \sum \frac{(x_i - \bar{x})^2}{(\hat{\sigma}^2)^3}
\end{array}\right] \\ \\
\text{Note que}\ \sum(x_i - \bar{x}) &= \sum x_i - n \bar{x} = \sum x_i - \sum x_i = 0 \\
\text{e que}\ \frac{n}{2(\hat{\sigma}^2)^2} - \frac{n\hat{\sigma}^2}{(\hat{\sigma}^2)^3} &= - \frac{n}{2(\hat{\sigma}^2)^2}\\ \\
\Rightarrow 
\left.\frac{\partial^2 \ln}{\partial \theta \partial \theta^T} \mathcal{L}_{\boldsymbol{x}_n}(\theta)\right\rvert_{\theta = \hat{\theta}} &=
\left[
\begin{array}{cc}
-\frac{n}{\hat{\sigma}^2} & 0 \\
0 & \frac{-n}{(\hat{\sigma}^2)^2}
\end{array}\right]
\end{aligned}
$$
desde que $\sum (x_i - \bar{x})^2 > 0$.

Como $\left.\frac{\partial^2 \ln}{\partial \theta \partial \theta^T} \mathcal{L}_{\boldsymbol{x}_n}(\theta)\right\rvert_{\theta = \hat{\theta}}$
é negativa definida, concluímos que $\hat{\theta}$ é pelo menos máximo local.
Dizemos que $\hat{\theta}_{\mathrm{MV}}(\boldsymbol{X}_n) = (\bar{X}, S^2_n)$ é o EMV para $\theta = (\mu, \sigma^2)$, em que
$$
S^2_n = \frac{1}{n} \sum (X_i - \bar{X})^2
$$

## Relação com a [Informação de Fisher](infofisher.qmd)

Note que a informação de Fisher total sob o [modelo normal anterior](emv2.qmd#sec-exnorm) é
$$
\begin{aligned}
I_n(\theta) &= - E_\theta\left(\frac{\partial^2 \ln}{\partial \theta \partial \theta^T} \mathcal{L}_{\boldsymbol{x}_n}(\theta)\right) \\
&= -E_\theta\left(
\begin{array}{cc}
-\frac{n}{\sigma^2} & -\frac{1}{\sigma^4} \sum (X_i - \mu) \\
-\frac{1}{\sigma^4} \sum (X_i - \mu) & \frac{n}{2\sigma^4} - \sum \frac{(X_i - \mu)^2}{(\sigma^2)^3}
\end{array}\right) \\
&= E_\theta\left(
\begin{array}{cc}
\frac{n}{\sigma^2} & \frac{1}{\sigma^4} \sum (X_i - \mu) \\
\frac{1}{\sigma^4} \sum (X_i - \mu) & -\frac{n}{2\sigma^4} + \sum \frac{(X_i - \mu)^2}{(\sigma^2)^3}
\end{array}\right) \\ \\
\text{Note que}\ E_\theta[(X_i-\mu)^2] &= \mathrm{Var}_\theta(X) = \sigma^2 \\ \\
\Rightarrow I_n (\theta) &= E_\theta\left(
\begin{array}{cc}
\frac{n}{\sigma^2} & 0 \\
0 & \frac{n}{2\sigma^4}
\end{array}\right).
\end{aligned}
$$

## Alguns exemplos

Seja $\pmb{X}_n$ a.a. de $X \sim f_\theta$,

1. $X \sim \mathrm{Ber}(\theta), \theta \in (0,1)$, o EMV para "$\theta$" é
$\hat{\theta}_{\mathrm{MV}}(\boldsymbol{X}_n) = \bar{X}$.

2. $X \sim \mathrm{Bin}(4, \theta), \theta \in (0,1)$, o EMV para "$\theta$" é
$\hat{\theta}_{\mathrm{MV}}(\boldsymbol{X}_n) = \frac{\bar{X}}{4}$.

3. $X \sim \mathrm{Poiss}(\theta), \theta > 0$, o EMV para "$\theta$" é
$\hat{\theta}_{\mathrm{MV}}(\boldsymbol{X}_n) = \bar{X}$.

4. $X \sim \mathrm{Exp}(\theta), \theta > 0$, o EMV para "$\theta$" é
$\hat{\theta}_{\mathrm{MV}}(\boldsymbol{X}_n) = \frac{1}{\bar{X}}$.

5. $X \sim f_\theta, \theta > 0,$ tal que
$$
f_\theta(x) = \left\{\begin{array}{ll}
\frac{1}{\Gamma(\theta)} x^{\theta-1} \mathrm{e}^{-x}, & x > 0 \\
0, & \mathrm{c.c.}
\end{array}\right.
$$
com $\Gamma(\theta) = \int x^{\theta-1} \mathrm{e}^{-x} dx$, temos
$$
\begin{aligned}
\mathcal{L}_{\pmb{x}_n}(\theta) &\stackrel{\mathrm{i.i.d.}}{=} \prod f_\theta(x_i)\\
&= \prod \left\{
\frac{1}{\Gamma(\theta)} x_i^{\theta-1} \mathrm{e}^{-x_i}\right\} \\
&= \frac{1}{\Gamma(\theta)^n} \left(\prod x_i\right)^{\theta-1} \mathrm{e}^{-\sum x_i} \\
\Rightarrow \ln \mathcal{L}_{\pmb{x}_n}(\theta) &= -n \ln \Gamma(\theta) + (\theta-1) \sum \ln x_i - \sum x_i \\
\\
\Rightarrow \frac{d\ln}{d\theta}\mathcal{L}_{\pmb{x}_n}(\theta) = 0 &\Rightarrow -\frac{n}{\Gamma(\theta)}\Gamma'(\theta) +
\sum \ln x_i  = 0.
\end{aligned}
$$

Como resolver:
$$
\sum \ln x_i = n \frac{\Gamma'(\theta)}{\Gamma(\theta)}.
$$

<!-- TODO: Método de Newton-Hapson, linkar -->
Posteriormente, encontraremos um método para encontrar essa solução.

6. $X \sim f_\theta, \theta \in \Theta$, em que $f_\theta$
pertence à [Família Exponencial $k$ dimensional](familia-exponencial.qmd#sec-fek), isto é,
$$
f_\theta(x) = \left\{\begin{array}{lr}
\mathrm{e}^{\sum^k_{j=1} c_j(\theta)T_j(x)+d(\theta)+S(x)}, &x \in \mathfrak{X} \\
0, & x \not \in \mathfrak{X}
\end{array}\right.
$$

A função verossimilhança para os valores observados $x_i \in \mathfrak{X}$ é dada por
$$
\begin{aligned}
\mathcal{L}_{\pmb{x}_n}(\theta) &\stackrel{\mathrm{i.i.d.}}{=} \prod \left\{
\mathrm{e}^{\sum^k_{j=1} c_j(\theta)T_j(x_i)+d(\theta)+S(x_i)}
\right\} \\
&= \mathrm{Exp}\left\{\sum_{j=1}^k c_j(\theta) \sum^n_{i=1} T_j(x_i) + nd(\theta) + \sum^n_{i=1} S(x_i)\right\} \\
\Rightarrow \ln \mathcal{L}_{\pmb{x}_n}(\theta) &= \sum_{j=1}^k c_j(\theta) \sum^n_{i=1} T_j(x_i) + nd(\theta) + \sum^n_{i=1} S(x_i)
\end{aligned}
$$

Se $c_1,\dots,c_k$ forem diferenciáveis com respeito a "$\theta$", temos que
$$
\frac{\partial \ln }{\partial \theta} \mathcal{L}_{\pmb{x}_n}(\theta) =  \sum^k_{j=1} \frac{\partial c_j(\theta}{\partial \theta}
\sum^n_{i=1} T_j(x_i) + n \frac{\partial d(\theta)}{\partial \theta}
$$
igualando a zero, temos que
$$
\sum^k_{j=1} \frac{\partial c_j(\theta)}{\partial \theta} \sum^n_{i=1} T(x_i) = - n \frac{\partial d(\theta)}{\partial \theta}
$${#eq-formageral}

:::{.callout-hint title="Uso de métodos numéricos"}
Em alguns casos, ([-@eq-formageral]) não tem solução fechada e utilizaremos um método numério para encontrar as soluções.
:::

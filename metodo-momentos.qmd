# Estimação pelo método de momentos

Seja $\boldsymbol{X}_n$ uma [a.a.](populacao-e-amostra.qmd#sec-aa) de $X$ tal que
$$
E_\theta (\lvert X \rvert^k) < \infty, k \in \{1,\dots,p\}, \Theta \subseteq \mathbb{R}^P
$$

O estimador obtido pelo método de momentos é aquele que satisfaz
$$
E_\theta(X^k) = \frac{1}{n} \sum^n_{i=1} X_i^k, k = 1, \dots, p.
$$

Note que a estimação pelo método de momentos *não* utiliza toda a informação contida na
[função de verossimilhança](funcao-verossimilhanca.qmd). Precisamos conhecer a forma dos primeiros $p$ momentos.

## Exemplo

Seja $\boldsymbol{X}_n$ a.a. de $X\sim U(0,\theta), \theta > 0$. Encontre o estimador pelo método de momentos.

Calcule o [EQM](eqm.qmd) do [EMV](emv2.qmd) e do estimador obtido pelo método de momentos.

### Resposta

Note que $\Theta = (0,\infty) \subseteq \mathbb{R}$. Portanto, $p=1$. Precisamos encontrar o valor de "$\theta$" que
satisfaz
$$
E_\theta(X) = \frac{1}{n} \sum X_i
$$

Sabemos que
$$
E_\theta \int^\theta_0 x \frac{1}{\theta} dx = \frac{\theta}{2} = \bar{X}
$$

Logo, $\hat{\theta}_{\mathrm{MM}}(\boldsymbol{X}_n) = 2\bar{X}$ é o estimador obtido pelo método de momentos.

Sabemos que $\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n) = \max\{X_1,\dots,X_n\}$, logo,
$$
\begin{aligned}
\mathrm{EQM}_\theta(\hat{\theta}_{\mathrm{MM}}(\pmb{X}_n), \theta) &= E_\theta((\hat{\theta}_{\mathrm{MM}}(\pmb{X}_n) - \theta)^2) \\
&=\mathrm{Var}_\theta(\hat{\theta}_{\mathrm{MM}}(\pmb{X}_n)) + \mathrm{Viés}(\hat{\theta}_{\mathrm{MM}}(\pmb{X}_n), \theta)^2 \\ \\
E_\theta(\hat{\theta}_{\mathrm{MM}}(\pmb{X}_n)) &= 2 E_\theta(X) = 2 \frac{\theta}{2} = \theta \\
\Rightarrow \mathrm{Viés}_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n),\theta) &= 0, \forall \theta \in \Theta. \\ \\
\mathrm{Var}_\theta(\hat{\theta}_{\mathrm{MM}}(\pmb{X}_n)) = \mathrm{Var}_\theta(2\bar{X}) &\stackrel{\mathrm{i.i.d.}}{=} 4 \frac{\mathrm{Var}_\theta(X)}{n}
\stackrel{\mathrm{Unif}}{=}  \frac{\theta^2}{3n} \\
\Rightarrow \mathrm{EQM}_\theta(\hat{\theta}_{\mathrm{MM}}(\pmb{X}_n),\theta) = \frac{\theta^2}{3n}
\end{aligned}
$$

Para o EMV,
$$
\mathrm{EQM}_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n), \theta) = \mathrm{Var}_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n))
+\mathrm{Viés}(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n), \theta)^2 \\ \\
$$

Precisaremos encontrar a distribuição do estimador,
$$
P_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n) \leq t) = P_\theta(\max\pmb{X}_n \leq t) \stackrel{\mathrm{iid}}{=} \prod P_\theta(X \leq t) = P_\theta(X \leq t)^n
$$
note que
$$
P_\theta(X \leq t) = \left\{\begin{array}{ll}
0, & t \leq 0 \\
\frac{t}{\theta}, & 0 < t \leq \theta \\
1, & t \geq \theta \\
\end{array}\right. \Rightarrow P_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n)\leq t)^n = \left\{\begin{array}{ll}
0, & t \leq 0 \\
\left(\frac{t}{\theta}\right)^n, & 0 < t \leq \theta \\
1, & t \geq \theta \\
\end{array}\right.
$$

Como $P_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n))$ é absoulatemente contínua para todo $\theta > 0$, temos que
$\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n)$ é uma variável aleatória contínua cuja f.d.p. é dada por
$$
f_\theta^{\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n)}(x) =\left. \frac{d}{dt} P_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n) \leq t) \right\rvert_{t=x}
= \left\{\begin{array}{ll}
\frac{n x^{n-1}}{\theta^n}, & 0 < x \leq \theta \\
0, & \mathrm{c.c.}
\end{array}\right. .
$$

Logo,
$$
\begin{aligned}
E_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n)) &= \int^{\infty}_{-\infty} w f_\theta^{\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n)}(w) dw \\
&= \int^\theta_0 w \frac{n w^{n-1}}{\theta^n} dw \\
&= \frac{n}{\theta^n} \int^\theta_0 w^n dw = \left.\frac{n}{\theta^n}\frac{w^{n+1}}{n+1} \right\rvert_{0}^\theta = \frac{n}{n+1}\theta, \forall \theta \in \Theta, \\
\Rightarrow E_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n)^2) &= \frac{n\theta^2}{n+2}, \forall \theta \in \Theta, \\
\Rightarrow \mathrm{Var}_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n)) &= \frac{n\theta^2}{n+2} - \left(\frac{n}{n+1}\right)^2\theta^2 \\
\Rightarrow \mathrm{EQM}_\theta(\hat{\theta}_{\mathrm{MV}}(\pmb{X}_n),\theta) &= \frac{n}{n+2}\theta^2 -
\frac{n^2}{(n+1)^2}\theta^2 + \left(\frac{n}{n+1}\theta - \theta\right)^2 \\
&= \theta^2\left(\frac{n}{n+2} - \frac{2}{n+1} + 1\right)
\end{aligned}
$$

```{julia}
#| echo: true
using Random, Distributions, StatsBase, Plots, LaTeXStrings

M = 10_000
n = 10
theta0 = rand(Poisson(4)) + 1

d = Uniform(0, theta0)

thetaMM = zeros(M)
thetaMV = zeros(M)
for i in 1:M
  x = rand(d, n)
  thetaMM[i] = 2*mean(x)
  thetaMV[i] = maximum(x)
end

# Comparar
println("Média simulada do EMM = $(mean(thetaMM)),
        calculada = $theta0")
println("Média simulada do EMV = $(mean(thetaMV)),
        calculada = $(10/11 * theta0)")
println("Variância simulada do EMM = $(var(thetaMM)),
        calculada = $(theta0^2 /(3*n))")
println("Variância simuladado EMV = $(var(thetaMV)),
        calculada = $(n * theta0^2 / (n+2) - (n/(n+1))^2 * theta0^2)")
```

